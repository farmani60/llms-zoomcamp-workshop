{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/results-gpt4o.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_orig</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The CONTEXT provided does not give specific in...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Where can I sign up for the course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You can sign up for the Machine Learning Zoomc...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Can you provide a link to sign up?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes, there is an FAQ for the Machine Learning ...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Is there an FAQ for this Machine Learning course?</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No, the provided context does not include any ...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Does this course have a GitHub repository for ...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To structure your questions and answers for th...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>How can I structure my questions and answers f...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          answer_llm  \\\n",
       "0  The CONTEXT provided does not give specific in...   \n",
       "1  You can sign up for the Machine Learning Zoomc...   \n",
       "2  Yes, there is an FAQ for the Machine Learning ...   \n",
       "3  No, the provided context does not include any ...   \n",
       "4  To structure your questions and answers for th...   \n",
       "\n",
       "                                         answer_orig  document  \\\n",
       "0  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "1  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "2  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "3  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "4  Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "\n",
       "                                            question  \\\n",
       "0                Where can I sign up for the course?   \n",
       "1                 Can you provide a link to sign up?   \n",
       "2  Is there an FAQ for this Machine Learning course?   \n",
       "3  Does this course have a GitHub repository for ...   \n",
       "4  How can I structure my questions and answers f...   \n",
       "\n",
       "                      course  \n",
       "0  machine-learning-zoomcamp  \n",
       "1  machine-learning-zoomcamp  \n",
       "2  machine-learning-zoomcamp  \n",
       "3  machine-learning-zoomcamp  \n",
       "4  machine-learning-zoomcamp  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_name = \"multi-qa-mpnet-base-dot-v1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 3.0.0.dev0, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_llm = df.iloc[0].answer_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emdedding = embedding_model.encode(answer_llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.23882452"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emdedding[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dot_product(embedding1, embedding2):\n",
    "    return np.dot(embedding1, embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = []\n",
    "for idx, row in df.iterrows():\n",
    "    emb_llm = embedding_model.encode(row['answer_llm'])\n",
    "    emb_orig = embedding_model.encode(row['answer_orig'])\n",
    "    score = compute_dot_product(emb_llm, emb_orig)\n",
    "    evaluations.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75th Percentile of Scores: 32.09545612335205\n"
     ]
    }
   ],
   "source": [
    "percentile_75 = np.percentile(evaluations, 75)\n",
    "\n",
    "print(\"75th Percentile of Scores:\", percentile_75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_vector(v):\n",
    "    norm = np.linalg.norm(v)\n",
    "    return v / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(embedding1, embedding2):\n",
    "    embedding1_norm = normalize_vector(embedding1)\n",
    "    embedding2_norm = normalize_vector(embedding2)\n",
    "    return np.dot(embedding1_norm, embedding2_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = []\n",
    "for idx, row in df.iterrows():\n",
    "    emb_llm = embedding_model.encode(row['answer_llm'])\n",
    "    emb_orig = embedding_model.encode(row['answer_orig'])\n",
    "    score = compute_cosine_similarity(emb_llm, emb_orig)\n",
    "    evaluations.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75th Percentile of Scores: 0.8348871618509293\n"
     ]
    }
   ],
   "source": [
    "percentile_75 = np.percentile(evaluations, 75)\n",
    "\n",
    "print(\"75th Percentile of Scores:\", percentile_75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge\n",
      "  Downloading rouge-1.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six in /home/codespace/.local/lib/python3.10/site-packages (from rouge) (1.16.0)\n",
      "Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: rouge\n",
      "Successfully installed rouge-1.0.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install rouge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = df[df['document'] == '5170565b'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1: {'r': 0.696969696969697, 'p': 0.5897435897435898, 'f': 0.6388888839236112}\n",
      "ROUGE-2: {'r': 0.43243243243243246, 'p': 0.34782608695652173, 'f': 0.3855421637334882}\n",
      "ROUGE-L: {'r': 0.6666666666666666, 'p': 0.5641025641025641, 'f': 0.6111111061458334}\n"
     ]
    }
   ],
   "source": [
    "rouge_scorer = Rouge()\n",
    "\n",
    "scores = rouge_scorer.get_scores(r['answer_llm'], r['answer_orig'])[0]\n",
    "\n",
    "print(\"ROUGE-1:\", scores['rouge-1'])\n",
    "print(\"ROUGE-2:\", scores['rouge-2'])\n",
    "print(\"ROUGE-L:\", scores['rouge-l'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE-1 F1: 0.6388888839236112\n",
      "ROUGE-2 F1: 0.3855421637334882\n",
      "ROUGE-L F1: 0.6111111061458334\n",
      "Average ROUGE F1: 0.545180717934311\n"
     ]
    }
   ],
   "source": [
    "rouge_1_f1 = scores['rouge-1']['f']\n",
    "rouge_2_f1 = scores['rouge-2']['f']\n",
    "rouge_l_f1 = scores['rouge-l']['f']\n",
    "\n",
    "average_rouge_f1 = (rouge_1_f1 + rouge_2_f1 + rouge_l_f1) / 3\n",
    "\n",
    "print(\"ROUGE-1 F1:\", rouge_1_f1)\n",
    "print(\"ROUGE-2 F1:\", rouge_2_f1)\n",
    "print(\"ROUGE-L F1:\", rouge_l_f1)\n",
    "print(\"Average ROUGE F1:\", average_rouge_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      rouge_1   rouge_2   rouge_l  rouge_avg\n",
      "0    0.187500  0.052632  0.187500   0.142544\n",
      "1    0.235294  0.103896  0.205882   0.181691\n",
      "2    0.289474  0.091954  0.236842   0.206090\n",
      "3    0.239130  0.035714  0.217391   0.164079\n",
      "4    0.155440  0.028269  0.145078   0.109596\n",
      "..        ...       ...       ...        ...\n",
      "295  0.772277  0.697248  0.752475   0.740667\n",
      "296  0.538462  0.413333  0.523077   0.491624\n",
      "297  0.624000  0.542857  0.624000   0.596952\n",
      "298  0.615385  0.517241  0.596154   0.576260\n",
      "299  0.561983  0.453901  0.561983   0.525956\n",
      "\n",
      "[300 rows x 4 columns]\n",
      "Average ROUGE-2 Score: 0.2014210455831726\n"
     ]
    }
   ],
   "source": [
    "rouge_scorer = Rouge()\n",
    "\n",
    "rouge_1_scores = []\n",
    "rouge_2_scores = []\n",
    "rouge_l_scores = []\n",
    "rouge_avg_scores = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    scores = rouge_scorer.get_scores(row['answer_llm'], row['answer_orig'])[0]\n",
    "    rouge_1 = scores['rouge-1']['f']\n",
    "    rouge_2 = scores['rouge-2']['f']\n",
    "    rouge_l = scores['rouge-l']['f']\n",
    "    rouge_avg = (rouge_1 + rouge_2 + rouge_l) / 3\n",
    "    \n",
    "    rouge_1_scores.append(rouge_1)\n",
    "    rouge_2_scores.append(rouge_2)\n",
    "    rouge_l_scores.append(rouge_l)\n",
    "    rouge_avg_scores.append(rouge_avg)\n",
    "\n",
    "scores_df = pd.DataFrame({\n",
    "    'rouge_1': rouge_1_scores,\n",
    "    'rouge_2': rouge_2_scores,\n",
    "    'rouge_l': rouge_l_scores,\n",
    "    'rouge_avg': rouge_avg_scores\n",
    "})\n",
    "\n",
    "average_rouge_2 = scores_df['rouge_2'].mean()\n",
    "\n",
    "\n",
    "print(scores_df)\n",
    "print(\"Average ROUGE-2 Score:\", average_rouge_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
